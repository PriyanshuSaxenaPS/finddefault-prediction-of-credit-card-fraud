{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95299a98-a2a3-4996-9537-c4593a9b60cd",
   "metadata": {},
   "source": [
    "## FindDefault (Prediction of Credit Card fraud)\n",
    "\n",
    "### Context\n",
    "Credit card companies need to spot fraud to avoid charging customers for unauthorized transactions.\n",
    "\n",
    "### Content\n",
    "This dataset has credit card transactions from European cardholders in September 2013. It includes 492 frauds out of 284,807 transactions, with frauds making up just 0.172% of all transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0c32d4-87e9-4c09-b839-76f0b378423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f305e51-406b-4149-984d-cf2c4f5aca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('../data/raw/creditcard.csv', sep=',')\n",
    "data1 = data.sample(frac=0.1, random_state=1)\n",
    "columns = data1.columns.tolist()\n",
    "columns = [c for c in columns if c not in [\"Class\"]]\n",
    "target = \"Class\"\n",
    "X = data1[columns]\n",
    "Y = data1[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0224ef-5c26-4c34-9bd0-1e836b7d44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine outlier fraction\n",
    "fraud = data1[data1['Class'] == 1]\n",
    "valid = data1[data1['Class'] == 0]\n",
    "outlier_fraction = len(fraud) / float(len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03518320-19ab-46a7-acd5-9710feecc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"Isolation Forest\": IsolationForest(n_estimators=100, max_samples=len(X), contamination=outlier_fraction, random_state=42),\n",
    "    \"Local Outlier Factor\": LocalOutlierFactor(n_neighbors=20, contamination=outlier_fraction),\n",
    "    \"Support Vector Machine\": OneClassSVM(kernel='rbf', gamma=0.1, nu=0.05)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefa282-a10f-447d-b192-d4ea3cb51b70",
   "metadata": {},
   "source": [
    "## Model Prediction\n",
    "\n",
    "We will use the following algorithms to detect anomalies in this dataset:\n",
    "\n",
    "### Isolation Forest Algorithm\n",
    "Isolation Forests detect anomalies by isolating data points that are few and different. This method is efficient because it uses isolation trees to separate anomalies, requiring fewer conditions compared to normal data. It performs well with less memory and processing time.\n",
    "\n",
    "### Local Outlier Factor (LOF) Algorithm\n",
    "LOF detects outliers by comparing the density of a data point to its neighbors. Points with significantly lower density than their neighbors are considered outliers. Typically, 20 neighbors are used for this comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d4a9d7-de9c-41d4-b0fd-cb0dc7dff3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest: 73\n",
      "Accuracy Score:\n",
      "0.9974368877497279\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.26      0.27      0.26        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.63      0.63      0.63     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "Local Outlier Factor: 97\n",
      "Accuracy Score:\n",
      "0.9965942207085425\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28432\n",
      "           1       0.02      0.02      0.02        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.51      0.51      0.51     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "Support Vector Machine: 8515\n",
      "Accuracy Score:\n",
      "0.7010287560127805\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82     28432\n",
      "           1       0.00      0.37      0.00        49\n",
      "\n",
      "    accuracy                           0.70     28481\n",
      "   macro avg       0.50      0.53      0.41     28481\n",
      "weighted avg       1.00      0.70      0.82     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "for clf_name, clf in classifiers.items():\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        y_pred = clf.fit_predict(X)\n",
    "        scores_prediction = clf.negative_outlier_factor_\n",
    "    elif clf_name == \"Support Vector Machine\":\n",
    "        clf.fit(X)\n",
    "        y_pred = clf.predict(X)\n",
    "    else:\n",
    "        clf.fit(X)\n",
    "        scores_prediction = clf.decision_function(X)\n",
    "        y_pred = clf.predict(X)\n",
    "    \n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    \n",
    "    n_errors = (y_pred != Y).sum()\n",
    "    print(f\"{clf_name}: {n_errors}\")\n",
    "    print(\"Accuracy Score:\")\n",
    "    print(accuracy_score(Y, y_pred))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(Y, y_pred))\n",
    "    \n",
    "    # Save the model\n",
    "    with open(f'../models/{clf_name.lower().replace(\" \", \"_\")}.pkl', 'wb') as model_file:\n",
    "        pickle.dump(clf, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a40e32d-9016-4dca-a4f1-567aace5239b",
   "metadata": {},
   "source": [
    "#### Observations :\n",
    "- Isolation Forest found 73 errors, LOF found 97 errors, and SVM found 8516 errors.\n",
    "- Isolation Forest is 99.74% accurate, better than LOF at 99.65% and SVM at 70.09%.\n",
    "- Isolation Forest detects about 27% of fraud cases, much better than LOF's 2% and SVM's 0%.\n",
    "- Overall, Isolation Forest is the best for identifying fraud, with about 30% accuracy.\n",
    "- Accuracy can be improved by using larger samples or deep learning, though it will be more computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fb04d-37f0-479c-bcd3-7be075dd754e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
